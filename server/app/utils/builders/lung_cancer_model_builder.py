# -*- coding: utf-8 -*-
"""covid19_notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OZHLzblu-qsc2HFZUnpJz74qqfp0poFK

"""

# Import necessary libraries
import joblib
import pandas as pd
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import MinMaxScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split


# Read the dataset from the csv file
data = pd.read_csv("../data/lung_cancer_dataset.csv")


# Specify the input features and the target variable
input_features = [
    "Gender",
    "Age",
    "Smoking",
    "YellowFingers",
    "Anxiety",
    "PeerPressure",
    "ChronicDisease",
    "Fatigue",
    "Allergy",
    "Wheezing",
    "AlcoholConsuming",
    "Coughing",
    "BreathShortage",
    "SwallowingDifficulty",
    "ChestPain",
]
target_variable = "LungCancer"


data_nontree = data.drop(target_variable, axis=1)


# Getting the target column at the end
data_nontree = pd.concat([data_nontree, data[target_variable]], axis=1)

feature_col_nontree = data_nontree.columns.to_list()
feature_col_nontree.remove(target_variable)

# Feature Scaling
scal = MinMaxScaler()
x_train = scal.fit_transform(data_nontree[feature_col_nontree].values)
y_train = data_nontree[target_variable]

joblib.dump(scal, "../models/lung_cancer/minmax_scaler_non_tree.pkl")

# Prepare the data for training and testing
x = data[input_features].astype(int)
y = data[target_variable].astype(int)

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)


# LOGISTIC REGRESSION
lg = LogisticRegression(max_iter=200)
lg.fit(x_train, y_train)

joblib.dump(lg, "../models/lung_cancer/logistic_regression.pkl")


# NAIVE BAYES
gnb = GaussianNB()
gnb.fit(x_train, y_train)

joblib.dump(gnb, "../models/lung_cancer/naive_bayes.pkl")


# KNN
knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(x_train, y_train)

joblib.dump(knn, "../models/lung_cancer/knn.pkl")


# DECISION TREE
dt = DecisionTreeClassifier()
dt.fit(x_train, y_train)

joblib.dump(dt, "../models/lung_cancer/decision_tree.pkl")


models = pd.DataFrame(
    {
        "Model": ["Logistic Regression", "Naive Bayes", "KNN", "Decision Tree"],
        "Score": [
            lg.score(x_test, y_test) * 100,
            gnb.score(x_test, y_test) * 100,
            knn.score(x_test, y_test) * 100,
            dt.score(x_test, y_test) * 100,
        ],
    }
)

print(models)

print("Done!")


# import joblib
# import numpy as np
# import pandas as pd
# from sklearn.naive_bayes import GaussianNB
# from sklearn.preprocessing import MinMaxScaler
# from sklearn.tree import DecisionTreeClassifier
# from sklearn.neighbors import KNeighborsClassifier
# from sklearn.linear_model import LogisticRegression
# from sklearn.model_selection import train_test_split


# print("Training all models...")

# # read csv using pandas library
# df = pd.read_csv("../data/lung_cancer.csv")

# # select numerical features and encoding it
# from sklearn.preprocessing import LabelEncoder

# string_col = df.select_dtypes(include="object").columns

# ## Creating one hot encoded features for working with non tree based algorithms
# from sklearn.preprocessing import OneHotEncoder
# from sklearn.compose import make_column_transformer

# target_col = "LungCancer"


# df_nontree = df.drop(target_col, axis=1)

# ohe = OneHotEncoder(handle_unknown="ignore")

# transformer = make_column_transformer(
#     (OneHotEncoder(), string_col),
#     remainder="passthrough",
#     verbose_feature_names_out=False,
# )

# transformed = transformer.fit_transform(df_nontree)
# df_nontree = pd.DataFrame(transformed, columns=transformer.get_feature_names_out())

# joblib.dump(transformer, "../models/lung_cancer/ohe_transformer.pkl")

# # Getting the target column at the end
# df_nontree = pd.concat([df_nontree, df[target_col]], axis=1)

# feature_col_nontree = df_nontree.columns.to_list()
# feature_col_nontree.remove("LungCancer")

# # Feature Scaling
# scal = MinMaxScaler()
# X_train = scal.fit_transform(df_nontree[feature_col_nontree].values)
# Y_train = df_nontree[target_col]

# joblib.dump(scal, "../models/lung_cancer/minmax_scaler_non_tree.pkl")


# # Prepare the data for training and testing
# X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.20)

# # LOGISTIC REGRESSION
# lg = LogisticRegression(max_iter=200)
# lg.fit(X_train, Y_train)

# joblib.dump(lg, "../models/lung_cancer/logistic_regression.pkl")


# # NAIVE BAYES
# gnb = GaussianNB()
# gnb.fit(X_train, Y_train)

# joblib.dump(gnb, "../models/lung_cancer/naive_bayes.pkl")

# # KNN
# knn = KNeighborsClassifier(n_neighbors=15)
# knn.fit(X_train, Y_train)

# joblib.dump(knn, "../models/lung_cancer/knn.pkl")


# # Label Ecoding
# # which will be used with Tree Based Algorithms

# df_tree = df.drop(np.insert(string_col, -1, target_col), axis=1)


# le = LabelEncoder()
# df_cat = df[string_col].apply(le.fit_transform)

# # Add back categorical features
# df_tree = pd.concat([df_tree, df_cat], axis=1)
# joblib.dump(le, "../models/lung_cancer/label_encoder.pkl")

# # Add back the target column
# df_tree = pd.concat([df_tree, df[target_col]], axis=1)

# feature_col_tree = df_tree.columns.to_list()
# feature_col_tree.remove(target_col)

# X_train = df_tree[feature_col_tree]
# Y_train = df_tree[target_col]

# dt = DecisionTreeClassifier(criterion="entropy")
# dt.fit(X_train, Y_train)

# # Saving the decision tree model
# joblib.dump(dt, "../models/lung_cancer/decision_tree.pkl")

# print("Build Models: OK\n")

# print("Checking accuracy...\n")

# models = pd.DataFrame(
#     {
#         "Model": ["Logistic Regression", "Naive Bayes", "KNN", "Decision Tree"],
#         "Score": [
#             lg.score(X_test, Y_test) * 100,
#             gnb.score(X_test, Y_test) * 100,
#             knn.score(X_test, Y_test) * 100,
#             dt.score(X_test, Y_test) * 100,
#         ],
#     }
# )


# print("Done")
